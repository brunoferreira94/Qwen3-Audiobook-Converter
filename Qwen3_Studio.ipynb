{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a97776",
   "metadata": {},
   "source": [
    "# Qwen3 Audiobook Studio (All in One)\n",
    "\n",
    "This notebook merges:\n",
    "- Qwen3-TTS features (voice cloning, custom voice, voice design)\n",
    "- Audiobook conversion (ebook or text to audiobook)\n",
    "- A single Gradio UI with tabs\n",
    "\n",
    "Notes:\n",
    "- The converter uses the local Gradio API at http://127.0.0.1:7860\n",
    "- The same app exposes the API and the UI\n",
    "- Recommended runtime: GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbded1",
   "metadata": {},
   "source": [
    "## 0) Check GPU (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344dad18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-7a02db82-230d-a6ec-4644-50b0d59b743b)\n",
      "torch: 2.10.0+cu128\n",
      "cuda available: True\n",
      "python: 3.12.11\n",
      "GPU optimizations enabled\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L || true\n",
    "import torch, platform\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"python:\", platform.python_version())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    try:\n",
    "        torch.set_float32_matmul_precision(\"high\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    print(\"GPU optimizations enabled\")\n",
    "else:\n",
    "    print(\"CUDA not available, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e963cdb2",
   "metadata": {},
   "source": [
    "## 1) Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71140ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 https://nvidia.github.io/libnvidia-container/stable/deb/amd64  InRelease [1477 B]\n",
      "Get:2 https://download.docker.com/linux/ubuntu noble InRelease [48.5 kB]       \n",
      "Get:3 https://cli.github.com/packages stable InRelease [3917 B]                \n",
      "Hit:4 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble InRelease          \n",
      "Get:5 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]\n",
      "Get:6 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]\n",
      "Get:7 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-security InRelease [126 kB]\n",
      "Get:8 https://security.ubuntu.com/ubuntu noble-security InRelease [126 kB]     \n",
      "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64  InRelease [1581 B]\n",
      "Get:10 https://packages.cloud.google.com/apt cloud-sdk InRelease [1620 B]      \n",
      "Get:11 https://download.docker.com/linux/ubuntu noble/stable amd64 Packages [54.3 kB]\n",
      "Get:12 https://download.docker.com/linux/ubuntu noble/stable amd64 Contents (deb) [1490 B]\n",
      "Get:13 https://cli.github.com/packages stable/main amd64 Packages [356 B]      \n",
      "Get:14 https://archive.ubuntu.com/ubuntu noble InRelease [256 kB]              \n",
      "Get:15 http://deb.wakemeops.com/wakemeops stable InRelease [50.5 kB]\n",
      "Get:16 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-updates/main amd64 Packages [2240 kB]\n",
      "Get:17 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-updates amd64 Contents (deb) [133 MB]\n",
      "Get:18 https://archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]      \n",
      "Get:19 https://archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]\n",
      "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64  Packages [1218 kB]\n",
      "Get:21 https://security.ubuntu.com/ubuntu noble-security/main amd64 Packages [1857 kB]\n",
      "Get:22 https://security.ubuntu.com/ubuntu noble-security amd64 Contents (deb) [125 MB]\n",
      "Get:23 https://packages.cloud.google.com/apt cloud-sdk/main all Packages [1940 kB]\n",
      "Get:24 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [4506 kB]\n",
      "Get:25 http://deb.wakemeops.com/wakemeops stable/dev amd64 Packages [164 kB]   \n",
      "Get:26 http://deb.wakemeops.com/wakemeops stable/dev amd64 Contents (deb) [249 kB]\n",
      "Get:27 https://archive.ubuntu.com/ubuntu noble/main amd64 Packages [1808 kB]   \n",
      "Get:28 http://deb.wakemeops.com/wakemeops stable/devops amd64 Packages [438 kB]\n",
      "Get:29 http://deb.wakemeops.com/wakemeops stable/secops amd64 Packages [87.4 kB]\n",
      "Get:30 http://deb.wakemeops.com/wakemeops stable/terminal amd64 Packages [116 kB]\n",
      "Get:31 http://deb.wakemeops.com/wakemeops stable/desktop amd64 Packages [21.6 kB]\n",
      "Get:32 https://archive.ubuntu.com/ubuntu noble amd64 Contents (deb) [51.3 MB]  \n",
      "Get:33 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-updates/universe amd64 Packages [2016 kB]\n",
      "Get:34 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Packages [3381 kB]\n",
      "Get:35 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-security/main amd64 Packages [1857 kB]\n",
      "Get:36 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-security amd64 Contents (deb) [125 MB]\n",
      "Get:37 https://archive.ubuntu.com/ubuntu noble/universe amd64 Packages [19.3 MB]\n",
      "Get:38 https://security.ubuntu.com/ubuntu noble-security/universe amd64 Packages [1207 kB]\n",
      "Get:39 https://security.ubuntu.com/ubuntu noble-security/restricted amd64 Packages [3196 kB]\n",
      "Get:40 https://archive.ubuntu.com/ubuntu noble/restricted amd64 Packages [117 kB]\n",
      "Get:41 https://archive.ubuntu.com/ubuntu noble/multiverse amd64 Packages [331 kB]\n",
      "Get:42 https://archive.ubuntu.com/ubuntu noble-updates/main amd64 Packages [2240 kB]\n",
      "Get:43 https://archive.ubuntu.com/ubuntu noble-updates amd64 Contents (deb) [133 MB]\n",
      "Get:44 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-security/universe amd64 Packages [1207 kB]\n",
      "Get:45 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-security/restricted amd64 Packages [3196 kB]\n",
      "Get:46 https://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-security/multiverse amd64 Packages [34.8 kB]\n",
      "Get:47 https://archive.ubuntu.com/ubuntu noble-updates/universe amd64 Packages [2016 kB]\n",
      "Get:48 https://archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Packages [3381 kB]\n",
      "Get:49 https://archive.ubuntu.com/ubuntu noble-updates/multiverse amd64 Packages [38.1 kB]\n",
      "Get:50 https://archive.ubuntu.com/ubuntu noble-backports/main amd64 Packages [49.5 kB]\n",
      "Get:51 https://archive.ubuntu.com/ubuntu noble-backports amd64 Contents (deb) [782 kB]\n",
      "Get:52 https://archive.ubuntu.com/ubuntu noble-backports/universe amd64 Packages [34.6 kB]\n",
      "Fetched 627 MB in 1min 48s (5806 kB/s)                                         \n",
      "Reading package lists... Done\n",
      "W: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "ffmpeg is already the newest version (7:6.1.1-3ubuntu5).\n",
      "sox is already the newest version (14.4.2+git20190427-4build4).\n",
      "lsof is already the newest version (4.95.0-1build3).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n",
      "Requirement already satisfied: pip in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (26.0.1)\n",
      "Requirement already satisfied: numpy<2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: qwen-tts in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.1.1)\n",
      "Requirement already satisfied: gradio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (6.6.0)\n",
      "Requirement already satisfied: gradio_client in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (2.1.0)\n",
      "Requirement already satisfied: num2words in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.5.14)\n",
      "Requirement already satisfied: regex in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (2026.2.19)\n",
      "Requirement already satisfied: soundfile in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.13.1)\n",
      "Requirement already satisfied: huggingface_hub in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.36.2)\n",
      "Collecting huggingface_hub\n",
      "  Using cached huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests==2.32.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (2.32.4)\n",
      "Requirement already satisfied: transformers>=4.52.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (4.57.3)\n",
      "Collecting transformers>=4.52.0\n",
      "  Using cached transformers-5.2.0-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: accelerate in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.2.1)\n",
      "Requirement already satisfied: tokenizers in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.22.2)\n",
      "Requirement already satisfied: torchvision in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (0.25.0)\n",
      "Requirement already satisfied: scipy>=1.13.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (1.17.0)\n",
      "Requirement already satisfied: scikit-learn>=1.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: pandas>=2.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests==2.32.4) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests==2.32.4) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests==2.32.4) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from requests==2.32.4) (2026.1.4)\n",
      "Requirement already satisfied: librosa in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from qwen-tts) (0.11.0)\n",
      "Requirement already satisfied: torchaudio in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from qwen-tts) (2.10.0)\n",
      "Requirement already satisfied: sox in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from qwen-tts) (1.5.0)\n",
      "Requirement already satisfied: onnxruntime in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from qwen-tts) (1.24.1)\n",
      "Requirement already satisfied: einops in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from qwen-tts) (0.8.2)\n",
      "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers>=4.52.0) (3.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers>=4.52.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers>=4.52.0) (6.0.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers>=4.52.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from transformers>=4.52.0) (4.67.3)\n",
      "Requirement already satisfied: psutil in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from accelerate) (7.2.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from accelerate) (2.10.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface_hub) (2026.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from huggingface_hub) (4.15.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (4.12.1)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (1.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (0.128.1)\n",
      "Requirement already satisfied: ffmpy in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (1.0.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (3.11.7)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (12.1.1)\n",
      "Requirement already satisfied: pydantic<=3.0,>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (2.12.5)\n",
      "Requirement already satisfied: pydub in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (0.0.22)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (2025.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.7 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (0.1.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (0.50.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (0.24.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from gradio) (0.40.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pandas>=2.2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from fastapi<1.0,>=0.115.2->gradio) (0.0.4)\n",
      "Requirement already satisfied: httpcore==1.* in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pydantic<=3.0,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pydantic<=3.0,>=2.0->gradio) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pydantic<=3.0,>=2.0->gradio) (0.4.2)\n",
      "Requirement already satisfied: click>=8.2.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=12.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (14.3.2)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from num2words) (0.6.2)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (82.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch>=2.0.0->accelerate) (1.3.4)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn>=1.5.0) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from scikit-learn>=1.5.0) (3.6.0)\n",
      "Requirement already satisfied: pycparser in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from cffi>=1.0->soundfile) (3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.2.0) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich>=12.3.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from rich>=12.3.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from librosa->qwen-tts) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from librosa->qwen-tts) (0.64.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from librosa->qwen-tts) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from librosa->qwen-tts) (1.9.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from librosa->qwen-tts) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from librosa->qwen-tts) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from librosa->qwen-tts) (1.1.2)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from numba>=0.51.0->librosa->qwen-tts) (0.46.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from pooch>=1.1->librosa->qwen-tts) (4.5.1)\n",
      "Requirement already satisfied: flatbuffers in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from onnxruntime->qwen-tts) (25.12.19)\n",
      "Requirement already satisfied: protobuf in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from onnxruntime->qwen-tts) (6.33.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: flash-attn in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (2.8.3)\n",
      "Requirement already satisfied: torch in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from flash-attn) (2.10.0)\n",
      "Requirement already satisfied: einops in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from flash-attn) (0.8.2)\n",
      "Requirement already satisfied: filelock in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (3.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (82.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (2026.2.0)\n",
      "Requirement already satisfied: cuda-bindings==12.9.4 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (12.9.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.6.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from torch->flash-attn) (3.6.0)\n",
      "Requirement already satisfied: cuda-pathfinder~=1.1 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from cuda-bindings==12.9.4->torch->flash-attn) (1.3.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages (from jinja2->torch->flash-attn) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get update\n",
    "!sudo apt-get install -y ffmpeg sox lsof\n",
    "!pip  install -U pip\n",
    "# pin requests to keep Colab compatibility (google-colab requires requests==2.32.4)\n",
    "# Force upgrade of scientific stack but KEEP numpy < 2.0 to avoid binary incompatibilities with Gradio/Matplotlib\n",
    "%pip install \"numpy<2.0\" -U qwen-tts gradio gradio_client num2words regex soundfile huggingface_hub \"requests==2.32.4\" \"transformers>=4.52.0\" accelerate sentencepiece tokenizers torchvision \"scipy>=1.13.0\" \"scikit-learn>=1.5.0\" \"pandas>=2.2.0\"\n",
    "\n",
    "# Optional: FlashAttention (can fail, safe to ignore)\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        %pip install -U flash-attn --no-build-isolation\n",
    "except Exception as e:\n",
    "    print(\"flash-attn install failed, continuing:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51530b0",
   "metadata": {},
   "source": [
    "## 2) Clone audiobook converter repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11e9649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local repo: /teamspace/studios/this_studio/Qwen3-Audiobook-Converter\n",
      "/teamspace/studios/this_studio/Qwen3-Audiobook-Converter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Prefer local repo; clone automatically if missing\n",
    "REPO = \"https://github.com/brunoferreira94/Qwen3-Audiobook-Converter.git\"\n",
    "DEST = \"/teamspace/studios/this_studio/Qwen3-Audiobook-Converter\"\n",
    "\n",
    "if os.path.exists(DEST):\n",
    "    print(\"Using local repo:\", DEST)\n",
    "else:\n",
    "    print(\"Local repo not found. Cloning:\", REPO)\n",
    "    !git clone --depth 1 {REPO} {DEST}\n",
    "\n",
    "%cd {DEST}\n",
    "!pip -q install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61eaa3",
   "metadata": {},
   "source": [
    "## 3) Launch unified Gradio app\n",
    "\n",
    "This single app provides:\n",
    "- Voice cloning (Base model)\n",
    "- Custom voices (CustomVoice model)\n",
    "- Voice design (VoiceDesign model)\n",
    "- Audiobook conversion (uses the same local API)\n",
    "\n",
    "The app runs on port 7860."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a2a9751",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import signal\n",
    "import subprocess\n",
    "\n",
    "def _kill_port_7860():\n",
    "    pids = []\n",
    "    for cmd in ([\"/usr/sbin/lsof\", \"-t\", \"-i:7860\"], [\"lsof\", \"-t\", \"-i:7860\"], [\"fuser\", \"-k\", \"7860/tcp\"]):\n",
    "        try:\n",
    "            out = subprocess.check_output(cmd, stderr=subprocess.STDOUT).decode().strip()\n",
    "            if cmd[0] == \"fuser\":\n",
    "                return True\n",
    "            if out:\n",
    "                pids = out.split()\n",
    "                break\n",
    "        except Exception:\n",
    "            continue\n",
    "    for pid in pids:\n",
    "        try:\n",
    "            os.kill(int(pid), signal.SIGKILL)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return bool(pids)\n",
    "\n",
    "killed = _kill_port_7860()\n",
    "print(\"Port 7860 cleared\" if killed else \"No process found on port 7860\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37230edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2026-02-22 14:35:41.587118531 [W:onnxruntime:Default, device_discovery.cc:211 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:91 ReadFileContents Failed to open file: \"/sys/class/drm/card0/device/vendor\"\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://4dc8196607cc3c062b.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4dc8196607cc3c062b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/gradio/queueing.py\", line 766, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/gradio/route_utils.py\", line 355, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/gradio/blocks.py\", line 2157, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/gradio/blocks.py\", line 1634, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/anyio/to_thread.py\", line 63, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2502, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 986, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/gradio/utils.py\", line 1038, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_12453/3153612340.py\", line 356, in transcribe_audio_api\n",
      "    result = pipe(audio)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 275, in __call__\n",
      "    return super().__call__(inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/pipelines/base.py\", line 1459, in __call__\n",
      "    return next(\n",
      "           ^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py\", line 126, in __next__\n",
      "    item = next(self.iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/pipelines/pt_utils.py\", line 271, in __next__\n",
      "    processed = self.infer(next(self.iterator), **self.params)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/pipelines/base.py\", line 1374, in forward\n",
      "    model_outputs = self._forward(model_inputs, **forward_params)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/pipelines/automatic_speech_recognition.py\", line 542, in _forward\n",
      "    tokens = self.model.generate(**generate_kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py\", line 679, in generate\n",
      "    timestamp_begin = self._set_return_timestamps(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/models/whisper/generation_whisper.py\", line 1402, in _set_return_timestamps\n",
      "    raise ValueError(\n",
      "ValueError: You have passed more than 3000 mel input features (> 30 seconds) which automatically enables long-form generation which requires the model to predict timestamp tokens. Please either pass `return_timestamps=True` or make sure to pass no more than 3000 mel input features.\n"
     ]
    }
   ],
   "source": [
    "import os, pathlib, shutil, subprocess, zipfile, tempfile, re, json, time, gc, contextlib\n",
    "import gradio as gr\n",
    "import torch\n",
    "import soundfile as sf\n",
    "from num2words import num2words\n",
    "from qwen_tts import Qwen3TTSModel\n",
    "from transformers import pipeline\n",
    "\n",
    "REPO_DIR = DEST if \"DEST\" in globals() else \"/teamspace/studios/this_studio/Qwen3-Audiobook-Converter\"\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    raise FileNotFoundError(f\"Repo not found: {REPO_DIR}\")\n",
    "\n",
    "BOOK_DIR = os.path.join(REPO_DIR, \"book_to_convert\")\n",
    "OUT_DIR  = os.path.join(REPO_DIR, \"audiobooks\")\n",
    "VOICES_DIR = os.path.join(REPO_DIR, \"saved_voices\") # Directory for saved voices\n",
    "\n",
    "pathlib.Path(BOOK_DIR).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(VOICES_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "AUDIO_EXTS = {\".mp3\", \".wav\", \".m4a\", \".flac\", \".ogg\"}\n",
    "\n",
    "MODEL_BASE = \"Qwen/Qwen3-TTS-12Hz-1.7B-Base\"\n",
    "MODEL_CUSTOM = \"Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice\"\n",
    "MODEL_DESIGN = \"Qwen/Qwen3-TTS-12Hz-1.7B-VoiceDesign\"\n",
    "\n",
    "current_model = None\n",
    "current_model_type = None\n",
    "\n",
    "# --- GPU / dtype helpers ---\n",
    "def _torch_dtype():\n",
    "    return torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "def _autocast():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.amp.autocast(device_type=\"cuda\", dtype=_torch_dtype())\n",
    "    return contextlib.nullcontext()\n",
    "\n",
    "def _cleanup():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# --- Model loader (single shared) ---\n",
    "def load_model(model_type: str):\n",
    "    global current_model, current_model_type\n",
    "\n",
    "    if current_model_type == model_type and current_model is not None:\n",
    "        return current_model\n",
    "\n",
    "    if current_model is not None:\n",
    "        del current_model\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    if model_type == \"base\":\n",
    "        model_name = MODEL_BASE\n",
    "    elif model_type == \"custom\":\n",
    "        model_name = MODEL_CUSTOM\n",
    "    elif model_type == \"design\":\n",
    "        model_name = MODEL_DESIGN\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type\")\n",
    "\n",
    "    current_model = Qwen3TTSModel.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    "        dtype=_torch_dtype(),\n",
    "        attn_implementation=\"sdpa\"\n",
    "    )\n",
    "    current_model_type = model_type\n",
    "    return current_model\n",
    "\n",
    "# --- I/O helpers ---\n",
    "def _write_wav(wavs, sr):\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
    "    sf.write(temp_file.name, wavs[0], sr)\n",
    "    return temp_file.name\n",
    "\n",
    "# --- Saved Voices Helpers ---\n",
    "def list_saved_voices():\n",
    "    if not os.path.exists(VOICES_DIR):\n",
    "        return []\n",
    "    return sorted([f.name for f in pathlib.Path(VOICES_DIR).glob(\"*\") if f.suffix.lower() in AUDIO_EXTS])\n",
    "\n",
    "def save_new_voice(audio_file, voice_name):\n",
    "    if not audio_file:\n",
    "        return \"Please upload an audio file first.\", list_saved_voices()\n",
    "    if not voice_name or not voice_name.strip():\n",
    "        return \"Please provide a name for the voice.\", list_saved_voices()\n",
    "    \n",
    "    # Sanitize filename\n",
    "    safe_name = re.sub(r'[^\\w\\-_\\. ]', '_', voice_name.strip())\n",
    "    original_ext = pathlib.Path(audio_file).suffix\n",
    "    if not safe_name.endswith(original_ext):\n",
    "        safe_name += original_ext\n",
    "        \n",
    "    dest_path = os.path.join(VOICES_DIR, safe_name)\n",
    "    shutil.copy(audio_file, dest_path)\n",
    "    \n",
    "    return f\"Voice '{safe_name}' saved successfully!\", list_saved_voices()\n",
    "\n",
    "def get_voice_path(voice_name):\n",
    "    if not voice_name:\n",
    "        return None\n",
    "    p = os.path.join(VOICES_DIR, voice_name)\n",
    "    if os.path.exists(p):\n",
    "        return p\n",
    "    return None\n",
    "\n",
    "def delete_saved_voice(voice_name):\n",
    "    if not voice_name:\n",
    "        return \"No voice selected.\", list_saved_voices()\n",
    "    p = os.path.join(VOICES_DIR, voice_name)\n",
    "    if os.path.exists(p):\n",
    "        os.remove(p)\n",
    "        return f\"Voice '{voice_name}' deleted.\", list_saved_voices()\n",
    "    return \"Voice not found.\", list_saved_voices()\n",
    "\n",
    "def refresh_voices_dropdown():\n",
    "    return gr.Dropdown(choices=list_saved_voices())\n",
    "\n",
    "# --------------------------\n",
    "# Language / normalization helpers (restored)\n",
    "# --------------------------\n",
    "# simple heuristics used by detect_lang_auto\n",
    "_PT_HINTS = re.compile(r\"\\b(que|não|para|com|uma|você|vocês|também|mais|menos|porque|pois|então|como|quando|onde|capítulo|prefácio|introdução)\\b\", re.IGNORECASE)\n",
    "_EN_HINTS = re.compile(r\"\\b(the|and|or|you|your|with|from|that|this|there|because|then|how|when|where|chapter|preface|introduction)\\b\", re.IGNORECASE)\n",
    "\n",
    "def detect_lang_auto(text: str) -> str:\n",
    "    \"\"\"Decide 'pt' or 'en' based on simple keyword heuristics and Portuguese diacritics.\"\"\"\n",
    "    if not text:\n",
    "        return \"pt\"\n",
    "    pt = len(_PT_HINTS.findall(text))\n",
    "    en = len(_EN_HINTS.findall(text))\n",
    "    if pt == en:\n",
    "        if re.search(r\"[ãõçáéíóúâêôà]\", text, re.IGNORECASE):\n",
    "            return \"pt\"\n",
    "    return \"en\" if en > pt else \"pt\"\n",
    "\n",
    "def _norm_language(lang: str) -> str:\n",
    "    \"\"\"Normalize incoming language strings for TTS/numbers. Returns 'pt','en' or 'Auto'.\"\"\"\n",
    "    if lang is None:\n",
    "        return \"pt\"\n",
    "    s = str(lang).strip()\n",
    "    if s == \"\":\n",
    "        return \"pt\"\n",
    "    low = s.lower()\n",
    "    if low in (\"auto\", \"auto-detect\"):\n",
    "        return \"Auto\"\n",
    "    if low.startswith(\"pt\"):\n",
    "        return \"pt\"\n",
    "    if low.startswith(\"en\"):\n",
    "        return \"en\"\n",
    "    if low in (\"english\", \"ingles\", \"inglês\"):\n",
    "        return \"en\"\n",
    "    if low in (\"portuguese\", \"portugues\", \"português\"):\n",
    "        return \"pt\"\n",
    "    return \"pt\"\n",
    "\n",
    "def _norm_speaker(spk: str) -> str:\n",
    "    \"\"\"Normalize speaker name to one of the known custom voices (case-insensitive).\n",
    "    Falls back to 'ryan' when unknown.\"\"\"\n",
    "    if spk is None:\n",
    "        return CUSTOM_VOICES[0] if CUSTOM_VOICES else \"ryan\"\n",
    "    s = str(spk).strip()\n",
    "    if s == \"\":\n",
    "        return CUSTOM_VOICES[0] if CUSTOM_VOICES else \"ryan\"\n",
    "    low = s.lower()\n",
    "    for x in CUSTOM_VOICES:\n",
    "        if x.lower() == low:\n",
    "            return x\n",
    "    # allow a few common aliases\n",
    "    aliases = {\"male\": \"ryan\", \"female\": \"serena\"}\n",
    "    if low in aliases:\n",
    "        return aliases[low]\n",
    "    return CUSTOM_VOICES[0] if CUSTOM_VOICES else \"ryan\"\n",
    "\n",
    "def spell_digits(text: str, lang: str) -> str:\n",
    "    lang_eff = resolve_lang(lang)\n",
    "    dmap = DIGITS_PT if lang_eff == \"pt\" else DIGITS_EN\n",
    "    smap = SEP_PT if lang_eff == \"pt\" else SEP_EN\n",
    "    out = []\n",
    "    for ch in text:\n",
    "        if ch.isdigit():\n",
    "            out.append(dmap.get(ch, ch))\n",
    "        elif ch in smap:\n",
    "            out.append(\" \" if ch == \" \" else smap[ch])\n",
    "        else:\n",
    "            out.append(ch)\n",
    "\n",
    "    final = []\n",
    "    for tok in out:\n",
    "        if tok == \" \":\n",
    "            final.append(\" \")\n",
    "        else:\n",
    "            if final and final[-1] != \" \":\n",
    "                final.append(\" \")\n",
    "            final.append(tok)\n",
    "    return \"\".join(final).replace(\"  \", \" \").strip()\n",
    "\n",
    "def speak_protected(kind: str, original: str, lang: str) -> str:\n",
    "    \"\"\"Return a spoken form for protected tokens (ISBN, VERSION, etc.).\"\"\"\n",
    "    s = original.strip()\n",
    "    lang_eff = resolve_lang(lang, ) if 'resolve_lang' in globals() else (\"pt\" if (lang or \"\").lower().startswith(\"pt\") else \"en\")\n",
    "\n",
    "    if kind == \"VERSION\":\n",
    "        if re.match(r\"^v\\d\", s, re.IGNORECASE):\n",
    "            s2 = s[1:]\n",
    "            prefix = \"versão \" if lang_eff == \"pt\" else \"version \"\n",
    "            return prefix + spell_digits(s2, lang_eff)\n",
    "        return spell_digits(s, lang_eff)\n",
    "\n",
    "    if kind == \"ISBN\":\n",
    "        rest = re.sub(r\"^ISBN(?:-1[03])?:?\\s*\", \"\", s, flags=re.IGNORECASE)\n",
    "        return \"ISBN \" + spell_digits(rest, lang_eff)\n",
    "\n",
    "    return spell_digits(s, lang_eff)\n",
    "\n",
    "# --------------------------\n",
    "# TTS generation functions\n",
    "# --------------------------\n",
    "def voice_clone(text, reference_audio, saved_voice, ref_transcript, use_fast_mode):\n",
    "    # Determine which audio to use: uploaded > saved\n",
    "    audio_path = reference_audio\n",
    "    if not audio_path and saved_voice:\n",
    "        audio_path = get_voice_path(saved_voice)\n",
    "\n",
    "    if not text or not audio_path:\n",
    "        return None\n",
    "        \n",
    "    model = load_model(\"base\")\n",
    "    if use_fast_mode or not ref_transcript:\n",
    "        prompt_items = model.create_voice_clone_prompt(\n",
    "            ref_audio=audio_path,\n",
    "            x_vector_only_mode=True\n",
    "        )\n",
    "    else:\n",
    "        prompt_items = model.create_voice_clone_prompt(\n",
    "            ref_audio=audio_path,\n",
    "            ref_text=ref_transcript,\n",
    "            x_vector_only_mode=False\n",
    "        )\n",
    "    with torch.inference_mode():\n",
    "        with _autocast():\n",
    "            wavs, sr = model.generate_voice_clone(\n",
    "                text=text,\n",
    "                voice_clone_prompt=prompt_items\n",
    "            )\n",
    "    out_path = _write_wav(wavs, sr)\n",
    "    _cleanup()\n",
    "    return out_path\n",
    "\n",
    "CUSTOM_VOICES = [\"serena\", \"vivian\", \"ono_anna\", \"sohee\", \"aiden\", \"dylan\", \"eric\", \"ryan\", \"uncle_fu\"]\n",
    "\n",
    "def custom_voice(text, voice_name, instruction):\n",
    "    if not text:\n",
    "        return None\n",
    "    model = load_model(\"custom\")\n",
    "    with torch.inference_mode():\n",
    "        with _autocast():\n",
    "            if instruction and instruction.strip():\n",
    "                wavs, sr = model.generate_custom_voice(\n",
    "                    text=text,\n",
    "                    speaker=voice_name,\n",
    "                    instruct=instruction\n",
    "                )\n",
    "            else:\n",
    "                wavs, sr = model.generate_custom_voice(\n",
    "                    text=text,\n",
    "                    speaker=voice_name\n",
    "                )\n",
    "    out_path = _write_wav(wavs, sr)\n",
    "    _cleanup()\n",
    "    return out_path\n",
    "\n",
    "def voice_design(text, voice_description):\n",
    "    if not text or not voice_description:\n",
    "        return None\n",
    "    model = load_model(\"design\")\n",
    "    with torch.inference_mode():\n",
    "        with _autocast():\n",
    "            wavs, sr = model.generate_voice_design(\n",
    "                text=text,\n",
    "                instruct=voice_description\n",
    "            )\n",
    "    out_path = _write_wav(wavs, sr)\n",
    "    _cleanup()\n",
    "    return out_path\n",
    "\n",
    "# API endpoint used by audiobook_converter.py\n",
    "def generate_custom_voice(text, language=\"Auto\", speaker=None, instruct=\"\", model_size=\"auto\", seed=0, **kwargs):\n",
    "    \"\"\"Public API (keeps original contract). Honors language variants like pt-BR by\n",
    "    appending a short instruction to bias accent when possible.\"\"\"\n",
    "    model = load_model(\"custom\")\n",
    "    spk = _norm_speaker(speaker)\n",
    "\n",
    "    # normalize language for model and build a helpful instruction\n",
    "    low = (language or \"\").strip().lower()\n",
    "    \n",
    "    # Map to model-compatible language codes (model expects 'english' not 'en', 'portuguese' not 'pt')\n",
    "    if low.startswith(\"pt\"):\n",
    "        lang_for_model = \"portuguese\"\n",
    "    elif low.startswith(\"en\"):\n",
    "        lang_for_model = \"english\"\n",
    "    else:\n",
    "        lang_for_model = low or \"Auto\"\n",
    "    \n",
    "    # add a short variant instruction (pt-BR / pt-PT) to bias accent when needed\n",
    "    variant_instr = \"\"\n",
    "    if low == \"pt-br\":\n",
    "        variant_instr = \"Use Brazilian Portuguese (pt-BR).\"\n",
    "    elif low == \"pt-pt\":\n",
    "        variant_instr = \"Use European Portuguese (pt-PT).\"\n",
    "\n",
    "    full_instr = (str(instruct or \"\").strip() + \" \" + variant_instr).strip()\n",
    "\n",
    "    try:\n",
    "        seed_int = int(seed) if seed is not None else 0\n",
    "        torch.manual_seed(seed_int)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed_int)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        with _autocast():\n",
    "            wavs, sr = model.generate_custom_voice(\n",
    "                text=text,\n",
    "                language=lang_for_model,\n",
    "                speaker=spk,\n",
    "                instruct=full_instr or \"\"\n",
    "            )\n",
    "    out_path = _write_wav(wavs, sr)\n",
    "    _cleanup()\n",
    "    return out_path, sr\n",
    "\n",
    "# --- Transcription helper ---\n",
    "_asr_pipeline = None\n",
    "def loaded_asr_pipeline():\n",
    "    global _asr_pipeline\n",
    "    if _asr_pipeline is None:\n",
    "        import torch\n",
    "        from transformers import pipeline\n",
    "        _asr_pipeline = pipeline(\n",
    "            \"automatic-speech-recognition\",\n",
    "            model=\"openai/whisper-tiny\", # Leve e rápido para demo\n",
    "            device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "    return _asr_pipeline\n",
    "\n",
    "def transcribe_audio_api(audio):\n",
    "    if not audio: return \"\"\n",
    "    pipe = loaded_asr_pipeline()\n",
    "    result = pipe(audio)\n",
    "    return result.get(\"text\", \"\")\n",
    "\n",
    "# --- Voice Clone API for audiobook_converter ---\n",
    "def generate_voice_clone_api_for_converter(ref_audio, ref_text, target_text, language=\"Auto\", use_xvector_only=False, model_size=\"1.7B\", max_chunk_chars=200, chunk_gap=0, seed=-1, **kwargs):\n",
    "    model = load_model(\"base\")\n",
    "    \n",
    "    try:\n",
    "        if seed is not None and int(seed) != -1:\n",
    "            torch.manual_seed(int(seed))\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.manual_seed_all(int(seed))\n",
    "    except: pass\n",
    "    \n",
    "    if not ref_text or not ref_text.strip():\n",
    "        # Fallback to xvector if no transcription\n",
    "        use_xvector_only = True\n",
    "\n",
    "    if use_xvector_only:\n",
    "        prompt_items = model.create_voice_clone_prompt(\n",
    "            ref_audio=ref_audio,\n",
    "            x_vector_only_mode=True\n",
    "        )\n",
    "    else:\n",
    "        prompt_items = model.create_voice_clone_prompt(\n",
    "            ref_audio=ref_audio,\n",
    "            ref_text=ref_text,\n",
    "            x_vector_only_mode=False\n",
    "        )\n",
    "        \n",
    "    with torch.inference_mode():\n",
    "        with _autocast():\n",
    "             wavs, sr = model.generate_voice_clone(\n",
    "                text=target_text,\n",
    "                voice_clone_prompt=prompt_items\n",
    "            )\n",
    "    \n",
    "    out_path = _write_wav(wavs, sr)\n",
    "    _cleanup()\n",
    "    return out_path, sr\n",
    "\n",
    "# --------------------------\n",
    "# TXT preprocessing / protection (uses speak_protected)\n",
    "# --------------------------\n",
    "PROTECT_PATTERNS = {\n",
    "    \"DATE_DDMMYYYY\": re.compile(r\"\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b\"),\n",
    "    \"DATE_YYYYMMDD\": re.compile(r\"\\b\\d{4}[/-]\\d{1,2}[/-]\\d{1,2}\\b\"),\n",
    "    \"TIME_HHMM\": re.compile(r\"\\b\\d{1,2}:\\d{2}\\b\"),\n",
    "    \"ISBN\": re.compile(r\"\\bISBN(?:-1[03])?:?\\s*(?:97[89][-\\s]?)?\\d{1,5}[-\\s]?\\d{1,7}[-\\s]?\\d{1,7}[-\\s]?\\d\\b\", re.IGNORECASE),\n",
    "    \"VERSION\": re.compile(r\"\\bv?\\d+\\.\\d+(?:\\.\\d+){0,3}\\b\", re.IGNORECASE),\n",
    "    \"LONG_ID\": re.compile(r\"\\b\\d{7,}\\b\"),\n",
    "    \"MIXED_CODE\": re.compile(r\"\\b[A-Z]{2,}\\d{2,}[A-Z0-9-]*\\b\"),\n",
    "}\n",
    "\n",
    "DIGITS_PT = {\"0\":\"zero\",\"1\":\"um\",\"2\":\"dois\",\"3\":\"tres\",\"4\":\"quatro\",\"5\":\"cinco\",\"6\":\"seis\",\"7\":\"sete\",\"8\":\"oito\",\"9\":\"nove\"}\n",
    "DIGITS_EN = {\"0\":\"zero\",\"1\":\"one\",\"2\":\"two\",\"3\":\"three\",\"4\":\"four\",\"5\":\"five\",\"6\":\"six\",\"7\":\"seven\",\"8\":\"eight\",\"9\":\"nine\"}\n",
    "SEP_PT = {\"/\":\"barra\",\"-\":\"traco\",\".\":\"ponto\",\":\":\"dois pontos\",\" \":\" \"}\n",
    "SEP_EN = {\"/\":\"slash\",\"-\":\"dash\",\".\":\"dot\",\":\":\"colon\",\" \":\" \"}\n",
    "\n",
    "def resolve_lang(lang: str) -> str:\n",
    "    \"\"\"Normalize language for number conversion: returns 'pt' or 'en'.\n",
    "    Accepts variants like 'pt-BR' and 'pt-PT'.\"\"\"\n",
    "    low = (lang or \"pt\").strip().lower()\n",
    "    if low == \"auto\":\n",
    "        return \"pt\"\n",
    "    if low.startswith(\"en\"):\n",
    "        return \"en\"\n",
    "    if low.startswith(\"pt\"):\n",
    "        return \"pt\"\n",
    "    return \"pt\"\n",
    "\n",
    "def spell_digits(text: str, lang: str) -> str:\n",
    "    lang_eff = resolve_lang(lang)\n",
    "    dmap = DIGITS_PT if lang_eff == \"pt\" else DIGITS_EN\n",
    "    smap = SEP_PT if lang_eff == \"pt\" else SEP_EN\n",
    "    out = []\n",
    "    for ch in text:\n",
    "        if ch.isdigit():\n",
    "            out.append(dmap.get(ch, ch))\n",
    "        elif ch in smap:\n",
    "            out.append(\" \" if ch == \" \" else smap[ch])\n",
    "        else:\n",
    "            out.append(ch)\n",
    "    return \" \".join([o for o in out if o != \"\"]).replace(\"  \", \" \").strip()\n",
    "\n",
    "def protect_text(text: str, enable: bool):\n",
    "    if not enable:\n",
    "        return text, {}\n",
    "    placeholder_map = {}\n",
    "    idx = 0\n",
    "    def _make_placeholder():\n",
    "        nonlocal idx\n",
    "        idx += 1\n",
    "        return f\"__KEEP_{idx:06d}__\"\n",
    "    for kind, pat in PROTECT_PATTERNS.items():\n",
    "        def repl(m, k=kind):\n",
    "            ph = _make_placeholder()\n",
    "            placeholder_map[ph] = {\"kind\": k, \"text\": m.group(0)}\n",
    "            return ph\n",
    "        text = pat.sub(repl, text)\n",
    "    return text, placeholder_map\n",
    "\n",
    "def unprotect_text(text: str, placeholder_map: dict, as_digits: bool, lang: str):\n",
    "    for ph, payload in placeholder_map.items():\n",
    "        original = payload[\"text\"]\n",
    "        kind = payload.get(\"kind\")\n",
    "        repl = speak_protected(kind, original, lang) if as_digits else original\n",
    "        text = text.replace(ph, repl)\n",
    "    return text\n",
    "\n",
    "def numbers_to_words_pt_en(text: str, lang: str) -> str:\n",
    "    def repl(m):\n",
    "        raw = m.group(0)\n",
    "\n",
    "        # lang auto: decide pelo contexto local (janela curta)\n",
    "        if (lang or \"\").strip().lower() == \"auto\":\n",
    "            # pega um pedacinho ao redor para detectar idioma\n",
    "            start = max(0, m.start() - 40)\n",
    "            end = min(len(text), m.end() + 40)\n",
    "            lang_eff = detect_lang_auto(text[start:end])\n",
    "        else:\n",
    "            lang_eff = resolve_lang(lang)\n",
    "\n",
    "        if \",\" in raw or \".\" in raw:\n",
    "            sep = \",\" if \",\" in raw else \".\"\n",
    "            left, right = raw.split(sep, 1)\n",
    "            try:\n",
    "                left_i = int(left); right_i = int(right)\n",
    "            except:\n",
    "                return raw\n",
    "            if lang_eff == \"pt\":\n",
    "                return f\"{num2words(left_i, lang='pt_BR')} vírgula {num2words(right_i, lang='pt_BR')}\"\n",
    "            else:\n",
    "                return f\"{num2words(left_i, lang='en')} point {num2words(right_i, lang='en')}\"\n",
    "        try:\n",
    "            n = int(raw)\n",
    "        except:\n",
    "            return raw\n",
    "        return num2words(n, lang=\"pt_BR\" if lang_eff == \"pt\" else \"en\")\n",
    "\n",
    "    pattern = re.compile(r\"(?<![A-Za-zÀ-ÿ_])(\\d{1,9}(?:[.,]\\d{1,3})?)(?![A-Za-zÀ-ÿ_])\")\n",
    "    return pattern.sub(repl, text)\n",
    "\n",
    "def _normalize_signature_lines(text: str) -> str:\n",
    "    \"\"\"Normalize citation/signature lines like '~ JOHN WOODEN' to natural case.\"\"\"\n",
    "    def repl(m):\n",
    "        name = m.group(1).strip()\n",
    "        name = re.sub(r\"\\s+\", \" \", name)\n",
    "        return \"— \" + name.title()\n",
    "    return re.sub(r\"(?m)^\\s*~\\s*([A-Z][A-Z\\s\\.'-]{2,})\\s*$\", repl, text)\n",
    "\n",
    "def preprocess_txt(input_txt: str, lang: str, pause_sec: float, do_numbers: bool, protect_codes: bool, protected_as_digits: bool, split_blocks: bool):\n",
    "    text = pathlib.Path(input_txt).read_text(encoding=\"utf-8\", errors=\"ignore\").replace(\"\\r\\n\",\"\\n\").replace(\"\\r\",\"\\n\")\n",
    "    text = _normalize_signature_lines(text)\n",
    "    text, keep = protect_text(text, enable=protect_codes)\n",
    "    if do_numbers:\n",
    "        text = numbers_to_words_pt_en(text, lang)\n",
    "    text = unprotect_text(text, keep, as_digits=protected_as_digits, lang=lang)\n",
    "    if pause_sec and pause_sec > 0:\n",
    "        text = re.sub(r\"\\n\\s*\\n\", \"\\n...\\n\", text)\n",
    "    if split_blocks:\n",
    "        paras = [p.strip() for p in text.split(\"\\n\") if p.strip()]\n",
    "        chunk_size = 140\n",
    "        chunks = [\"\\n\".join(paras[i:i+chunk_size]) for i in range(0, len(paras), chunk_size)]\n",
    "        text = \"\\n\\n\".join(chunks)\n",
    "    out_file = input_txt.replace(\".txt\", \"_processed.txt\")\n",
    "    pathlib.Path(out_file).write_text(text, encoding=\"utf-8\")\n",
    "    return out_file\n",
    "\n",
    "def loudnorm_measure(in_file: str, target_lufs: float, true_peak: float, lra: float):\n",
    "    cmd = [\"ffmpeg\",\"-hide_banner\",\"-y\",\"-i\",in_file,\"-af\",f\"loudnorm=I={target_lufs}:TP={true_peak}:LRA={lra}:print_format=json\",\"-f\",\"null\",\"-\"]\n",
    "    r = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    if r.returncode != 0:\n",
    "        raise RuntimeError(r.stdout[-1200:])\n",
    "    blocks = re.findall(r\"\\{[\\s\\S]*?\\}\", r.stdout)\n",
    "    if not blocks:\n",
    "        raise RuntimeError(\"Could not extract loudnorm JSON.\\n\" + r.stdout[-1200:])\n",
    "    return json.loads(blocks[-1])\n",
    "\n",
    "def loudnorm_apply_2pass(in_file: str, out_file: str, target_lufs: float, true_peak: float, lra: float, meas: dict):\n",
    "    fi = str(meas.get(\"input_i\")); ftp = str(meas.get(\"input_tp\"))\n",
    "    flra = str(meas.get(\"input_lra\")); fth = str(meas.get(\"input_thresh\"))\n",
    "    foff = str(meas.get(\"target_offset\"))\n",
    "    af = (f\"loudnorm=I={target_lufs}:TP={true_peak}:LRA={lra}:\"\n",
    "          f\"measured_I={fi}:measured_TP={ftp}:measured_LRA={flra}:\"\n",
    "          f\"measured_thresh={fth}:offset={foff}:linear=true:print_format=summary\")\n",
    "    cmd = [\"ffmpeg\",\"-hide_banner\",\"-y\",\"-i\",in_file,\"-af\",af,out_file]\n",
    "    r = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    if r.returncode != 0:\n",
    "        raise RuntimeError(r.stdout[-1200:])\n",
    "    return r.stdout\n",
    "\n",
    "def normalize_volume_folder_2pass(folder: str, target_lufs: float, true_peak: float, lra: float):\n",
    "    folder_path = pathlib.Path(folder)\n",
    "    files = [p for p in folder_path.rglob(\"*\") if p.is_file() and p.suffix.lower() in AUDIO_EXTS]\n",
    "    if not files:\n",
    "        return \"No audio found to normalize.\"\n",
    "    logs = []\n",
    "    for p in files:\n",
    "        tmp = p.with_suffix(\".normtmp\" + p.suffix)\n",
    "        try:\n",
    "            meas = loudnorm_measure(str(p), target_lufs, true_peak, lra)\n",
    "            loudnorm_apply_2pass(str(p), str(tmp), target_lufs, true_peak, lra, meas)\n",
    "            tmp.replace(p)\n",
    "            logs.append(f\"OK {p.name}: normalized (2-pass)\")\n",
    "        except Exception as e:\n",
    "            if tmp.exists():\n",
    "                tmp.unlink(missing_ok=True)\n",
    "            logs.append(f\"FAIL {p.name}: {str(e)[:800]}\")\n",
    "    return \"\\n\".join(logs[:220]) + (\"\\n... log truncated\" if len(logs) > 220 else \"\")\n",
    "\n",
    "def run_convert(book_file, lang, pause_sec, do_numbers, protect_codes, protected_as_digits, split_blocks, normalize_audio, target_lufs, true_peak, lra, ref_audio_file=None, saved_voice=None):\n",
    "    if book_file is None:\n",
    "        return \"Please upload a file first.\", None\n",
    "\n",
    "    for item in pathlib.Path(OUT_DIR).rglob(\"*\"):\n",
    "        if item.is_file():\n",
    "            item.unlink()\n",
    "\n",
    "    placeholder = os.path.join(BOOK_DIR, \"input_here.txt\")\n",
    "    if os.path.isfile(placeholder):\n",
    "        os.remove(placeholder)\n",
    "\n",
    "    dst = os.path.join(BOOK_DIR, os.path.basename(book_file))\n",
    "    shutil.copy(book_file, dst)\n",
    "\n",
    "    input_for_converter = dst\n",
    "    if dst.lower().endswith(\".txt\"):\n",
    "        input_for_converter = preprocess_txt(\n",
    "            dst, lang, pause_sec, do_numbers, protect_codes, protected_as_digits, split_blocks\n",
    "        )\n",
    "\n",
    "    # Build command arguments\n",
    "    cmd_args = [\"python\", \"audiobook_converter.py\"]\n",
    "    \n",
    "    # Check if using saved voice\n",
    "    if saved_voice:\n",
    "        voice_path = get_voice_path(saved_voice)\n",
    "        if voice_path:\n",
    "            ref_audio_file = voice_path\n",
    "\n",
    "    # Add voice clone args if reference audio is provided\n",
    "    if ref_audio_file:\n",
    "        cmd_args.append(\"--voice-clone\")\n",
    "        cmd_args.append(\"--voice-sample\")\n",
    "        cmd_args.append(ref_audio_file)\n",
    "    \n",
    "    p = subprocess.Popen(\n",
    "        cmd_args,\n",
    "        cwd=REPO_DIR,\n",
    "        stdin=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True\n",
    "    )\n",
    "    p.stdin.write(input_for_converter + \"\\n\")\n",
    "    p.stdin.flush()\n",
    "\n",
    "    logs = []\n",
    "    for line in p.stdout:\n",
    "        logs.append(line)\n",
    "    rc = p.wait()\n",
    "    log_text = \"\".join(logs)\n",
    "    if rc != 0:\n",
    "        return f\"Conversion failed (exit={rc}).\\n\\n{log_text[-9000:]}\", None\n",
    "\n",
    "    norm_text = \"\"\n",
    "    if normalize_audio:\n",
    "        norm_text += \"\\n\\n=== Loudness normalization ===\\n\"\n",
    "        norm_text += normalize_volume_folder_2pass(OUT_DIR, float(target_lufs), float(true_peak), float(lra))\n",
    "\n",
    "    zip_path = os.path.join(REPO_DIR, \"audiobooks_output.zip\")\n",
    "    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "        for pth in pathlib.Path(OUT_DIR).rglob(\"*\"):\n",
    "            if pth.is_file():\n",
    "                z.write(str(pth), str(pth.relative_to(REPO_DIR)))\n",
    "\n",
    "    return f\"Done.\\n\\n{log_text[-9000:]}{norm_text}\", zip_path\n",
    "\n",
    "with gr.Blocks(title=\"Qwen3 Audiobook Studio\") as demo:\n",
    "    gr.Markdown(\"# Qwen3 Audiobook Studio\")\n",
    "\n",
    "    # --- Saved Voices Tab ---\n",
    "    with gr.Tab(\"Saved Voices\"):\n",
    "        gr.Markdown(\"### Manage Your Voice Profiles\")\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                sv_upload = gr.Audio(label=\"Upload New Audio Sample\", type=\"filepath\")\n",
    "                sv_name = gr.Textbox(label=\"Voice Name (e.g., 'MyNarration')\")\n",
    "                sv_save_btn = gr.Button(\"Save Voice Profile\", variant=\"primary\")\n",
    "                sv_result = gr.Textbox(label=\"Status\")\n",
    "            \n",
    "            with gr.Column():\n",
    "                sv_list_box = gr.Dropdown(choices=list_saved_voices(), label=\"Existing Voices\", interactive=True)\n",
    "                sv_delete_btn = gr.Button(\"Delete Selected Voice\", variant=\"stop\")\n",
    "        \n",
    "        # Actions\n",
    "        sv_save_btn.click(\n",
    "            save_new_voice, \n",
    "            inputs=[sv_upload, sv_name], \n",
    "            outputs=[sv_result, sv_list_box]\n",
    "        )\n",
    "        \n",
    "        sv_delete_btn.click(\n",
    "            delete_saved_voice,\n",
    "            inputs=[sv_list_box],\n",
    "            outputs=[sv_result, sv_list_box]\n",
    "        )\n",
    "\n",
    "    with gr.Tab(\"Voice Cloning\"):\n",
    "        clone_text = gr.Textbox(label=\"Text\", lines=4)\n",
    "        with gr.Row():\n",
    "            clone_audio = gr.Audio(label=\"Reference audio (upload)\", type=\"filepath\")\n",
    "            clone_saved_voice = gr.Dropdown(label=\"OR Select a Saved Voice\", choices=list_saved_voices(), value=None)\n",
    "        \n",
    "        # When Saved Voices tab updates dropdown, we want this one to update too ideally. \n",
    "        # But Gradio doesn't sync across tabs easily without extra events. \n",
    "        # We'll just refresh list on click if needed or rely on app restart for now, \n",
    "        # OR we can link the save output to update this component too.\n",
    "        sv_save_btn.click(refresh_voices_dropdown, outputs=clone_saved_voice)\n",
    "        sv_delete_btn.click(refresh_voices_dropdown, outputs=clone_saved_voice)\n",
    "\n",
    "        clone_transcript = gr.Textbox(label=\"Transcript (optional)\", lines=3)\n",
    "        clone_fast_mode = gr.Checkbox(label=\"Fast mode\", value=True)\n",
    "        clone_btn = gr.Button(\"Generate\", variant=\"primary\")\n",
    "        clone_output = gr.Audio(label=\"Output\")\n",
    "        \n",
    "        clone_btn.click(\n",
    "            voice_clone, \n",
    "            inputs=[clone_text, clone_audio, clone_saved_voice, clone_transcript, clone_fast_mode], \n",
    "            outputs=clone_output\n",
    "        )\n",
    "\n",
    "    with gr.Tab(\"Custom Voice\"):\n",
    "        custom_text = gr.Textbox(label=\"Text\", lines=4)\n",
    "        custom_voice_name = gr.Dropdown(choices=CUSTOM_VOICES, value=\"serena\", label=\"Voice\")\n",
    "        custom_instruction = gr.Textbox(label=\"Style instruction (optional)\", lines=2)\n",
    "        custom_btn = gr.Button(\"Generate\", variant=\"primary\")\n",
    "        custom_output = gr.Audio(label=\"Output\")\n",
    "        custom_btn.click(custom_voice, inputs=[custom_text, custom_voice_name, custom_instruction], outputs=custom_output)\n",
    "\n",
    "    with gr.Tab(\"Voice Design\"):\n",
    "        design_text = gr.Textbox(label=\"Text\", lines=4)\n",
    "        design_description = gr.Textbox(label=\"Voice description\", lines=4)\n",
    "        design_btn = gr.Button(\"Generate\", variant=\"primary\")\n",
    "        design_output = gr.Audio(label=\"Output\")\n",
    "        design_btn.click(voice_design, inputs=[design_text, design_description], outputs=design_output)\n",
    "\n",
    "    with gr.Tab(\"Audiobook Conversion\"):\n",
    "        book = gr.File(label=\"Book file (PDF/EPUB/DOCX/TXT)\", type=\"filepath\")\n",
    "        lang = gr.Dropdown([\"auto\", \"pt-BR\", \"pt-PT\", \"en\"], value=\"auto\", label=\"Language for numbers\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            # Reference Audio input\n",
    "            ref_audio_input = gr.Audio(label=\"Reference Audio (Upload)\", type=\"filepath\")\n",
    "            # Saved Voice Select\n",
    "            ref_saved_voice = gr.Dropdown(label=\"OR Select Saved Voice\", choices=list_saved_voices(), value=None)\n",
    "            \n",
    "            sv_save_btn.click(refresh_voices_dropdown, outputs=ref_saved_voice)\n",
    "            sv_delete_btn.click(refresh_voices_dropdown, outputs=ref_saved_voice)\n",
    "\n",
    "        with gr.Accordion(\"TXT preprocessing\", open=True):\n",
    "            do_numbers = gr.Checkbox(value=True, label=\"Convert numbers to words (TXT only)\")\n",
    "            protect_codes = gr.Checkbox(value=True, label=\"Protect dates/ISBN/codes (TXT only)\")\n",
    "            protected_as_digits = gr.Checkbox(value=True, label=\"Read protected patterns as digits\")\n",
    "            pause_sec = gr.Slider(0, 3, value=0.0, step=0.5, label=\"Insert pause between paragraphs (seconds)\")\n",
    "            split_blocks = gr.Checkbox(value=False, label=\"Split TXT into blocks\")\n",
    "        with gr.Accordion(\"Audio post-processing\", open=True):\n",
    "            normalize_audio = gr.Checkbox(value=True, label=\"Normalize loudness (2-pass)\")\n",
    "            target_lufs = gr.Slider(-24, -12, value=-16, step=1, label=\"Target LUFS\")\n",
    "            true_peak = gr.Slider(-6, 0, value=-1.5, step=0.5, label=\"True peak (dBTP)\")\n",
    "            lra = gr.Slider(1, 20, value=11, step=1, label=\"LRA\")\n",
    "        convert_btn = gr.Button(\"Convert\", variant=\"primary\")\n",
    "        out_log = gr.Textbox(label=\"Logs\", lines=12)\n",
    "        out_zip = gr.File(label=\"Download ZIP\", elem_id=\"auto_zip_file\")\n",
    "        convert_evt = convert_btn.click(\n",
    "            run_convert,\n",
    "            inputs=[book, lang, pause_sec, do_numbers, protect_codes, protected_as_digits, split_blocks, normalize_audio, target_lufs, true_peak, lra, ref_audio_input, ref_saved_voice],\n",
    "            outputs=[out_log, out_zip]\n",
    "        )\n",
    "\n",
    "        convert_evt.then(\n",
    "            fn=None,\n",
    "            js=\"\"\"() => { setTimeout(() => { const link = document.querySelector('#auto_zip_file a[href]'); if (link) { link.click(); } }, 700); }\"\"\"\n",
    "        )\n",
    "\n",
    "        # --- Compatibility API for audiobook_converter.py ---\n",
    "        # Exposes /generate_custom_voice without changing converter code\n",
    "        with gr.Row(visible=False):\n",
    "            # API: generate_custom_voice\n",
    "            api_text = gr.Textbox(value=\"\", visible=False)\n",
    "            api_language = gr.Textbox(value=\"Auto\", visible=False)\n",
    "            api_speaker = gr.Textbox(value=\"ryan\", visible=False)\n",
    "            api_instruct = gr.Textbox(value=\"\", visible=False)\n",
    "            api_model_size = gr.Textbox(value=\"auto\", visible=False)\n",
    "            api_seed = gr.Number(value=0, visible=False)\n",
    "            api_audio = gr.Audio(type=\"filepath\", visible=False)\n",
    "            api_sr = gr.Number(visible=False)\n",
    "            api_btn = gr.Button(visible=False)\n",
    "            api_btn.click(\n",
    "                fn=generate_custom_voice,\n",
    "                inputs=[api_text, api_language, api_speaker, api_instruct, api_model_size, api_seed],\n",
    "                outputs=[api_audio, api_sr],\n",
    "                api_name=\"generate_custom_voice\"\n",
    "            )\n",
    "            \n",
    "            # API: transcribe_audio\n",
    "            api_trans_audio = gr.Audio(type=\"filepath\", visible=False)\n",
    "            api_trans_out = gr.Textbox(visible=False)\n",
    "            api_trans_btn = gr.Button(visible=False)\n",
    "            api_trans_btn.click(\n",
    "                fn=transcribe_audio_api,\n",
    "                inputs=[api_trans_audio],\n",
    "                outputs=[api_trans_out],\n",
    "                api_name=\"transcribe_audio\"\n",
    "            )\n",
    "            \n",
    "            # API: generate_voice_clone\n",
    "            api_vc_ref_audio = gr.Audio(type=\"filepath\", visible=False)\n",
    "            api_vc_ref_text = gr.Textbox(visible=False)\n",
    "            api_vc_target_text = gr.Textbox(visible=False)\n",
    "            api_vc_lang = gr.Textbox(visible=False)\n",
    "            api_vc_xvec = gr.Checkbox(visible=False)\n",
    "            api_vc_model = gr.Textbox(visible=False)\n",
    "            api_vc_chars = gr.Number(visible=False)\n",
    "            api_vc_gap = gr.Number(visible=False)\n",
    "            api_vc_seed = gr.Number(visible=False)\n",
    "            \n",
    "            api_vc_out = gr.Audio(visible=False)\n",
    "            api_vc_sr = gr.Number(visible=False)\n",
    "            \n",
    "            api_vc_btn = gr.Button(visible=False)\n",
    "            api_vc_btn.click(\n",
    "                fn=generate_voice_clone_api_for_converter,\n",
    "                inputs=[api_vc_ref_audio, api_vc_ref_text, api_vc_target_text, api_vc_lang, api_vc_xvec, api_vc_model, api_vc_chars, api_vc_gap, api_vc_seed],\n",
    "                outputs=[api_vc_out, api_vc_sr],\n",
    "                api_name=\"generate_voice_clone\"\n",
    "            )\n",
    "\n",
    "demo.queue(max_size=32)\n",
    "demo.launch(server_port=7860, share=True, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
